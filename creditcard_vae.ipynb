{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from vae import VAE\n",
    "from loss_function import loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file located at '/data' in parent directory\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), '..', 'data', 'creditcard.csv')) \n",
    "print(path)\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = df[df['Class']==0]\n",
    "normal_data = normal_data.reset_index(drop=True)\n",
    "display(normal_data.head())\n",
    "print(normal_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_data = df[df['Class']==1]\n",
    "novel_data = novel_data.reset_index(drop=True)\n",
    "display(novel_data.head())\n",
    "print(novel_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(normal_data.shape[0]*0.6) # 60% train\n",
    "valid_size = int(normal_data.shape[0]*0.2) # 20% valid\n",
    "test_size = int(normal_data.shape[0]*0.2) # 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_size)\n",
    "print(valid_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = normal_data[:train_size]\n",
    "valid_data = normal_data[train_size:train_size+valid_size]\n",
    "test_data = normal_data[train_size+valid_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_data.head())\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([test_data, novel_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test_data.head())\n",
    "\n",
    "display(test_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdims=2\n",
    "batch_size=128\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(zdims)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCFDataset(Dataset) : \n",
    "    def __init__(self, df, transform=transforms.ToTensor()) :\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        # x, y\n",
    "        return self.df.drop(['Class', 'Time'], axis=1).iloc[idx], self.df['Class'].iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CCFDataset(train_data)\n",
    "valid_data = CCFDataset(valid_data)\n",
    "test_data = CCFDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch) : \n",
    "    \n",
    "    train_loss = 0\n",
    "    loss_train = []\n",
    "    loss_valid = []\n",
    "    \n",
    "    # get loss for whole validation set\n",
    "    loss_valid.append(validate(1))\n",
    "    \n",
    "    model.train() # toggle train mode\n",
    "    \n",
    "    # get batch loss for train set and backpropate\n",
    "    for batch_idx, (data, _) in enumerate(train_loader) :\n",
    "        data = Variable(data)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Propagate\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        \n",
    "        # Get loss value\n",
    "        loss = loss_function(recon_batch, data, mu, logvar, batch_size)\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "            \n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "      \n",
    "    # append to list 'loss_train' instance to plot later\n",
    "    loss_train.append(train_loss / len(train_loader.dataset))\n",
    "    \n",
    "    return loss_train, loss_valid\n",
    "\n",
    "    \n",
    "def validate(epoch) : \n",
    "    model.eval() # toggle inference mode\n",
    "    valid_loss = 0\n",
    "    \n",
    "    \n",
    "    for i, (data, _) in enumerate(test_loader) :\n",
    "        data = Variable(data)\n",
    "        \n",
    "        # Propagate\n",
    "        with torch.no_grad() :\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "        \n",
    "        # Get loss value\n",
    "        valid_loss += loss_function(recon_batch, data, mu, logvar, batch_size).item()\n",
    "\n",
    "    valid_loss /= len(test_loader.dataset)\n",
    "    print('====> Validation set loss: {:.4f}'.format(valid_loss))\n",
    "    \n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train = []\n",
    "loss_valid = []\n",
    "lowest_valid_loss = 0\n",
    "best_model = copy.deepcopy(model)\n",
    "\n",
    "for epoch in range(1, epochs+1) :\n",
    "    temp_train, temp_valid = train(epoch)\n",
    "    \n",
    "    if epoch == 1 :\n",
    "        lowest_valid_loss = temp_valid\n",
    "    else :\n",
    "        if temp_valid <= lowest_valid_loss :\n",
    "            lowest_valid_loss = temp_valid\n",
    "            best_model = copy.deepcopy(model)\n",
    "            \n",
    "    loss_train.append(temp_train)\n",
    "    loss_valid.append(temp_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
